# Seq_2_Seq_Multihead_attention_model
This repository contains a working code for training a Sequence to Sequence transformer model from scratch using Torch.
